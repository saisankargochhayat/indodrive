{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'solidWhiteRight.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a1ae45a6f8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reading in an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'solidWhiteRight.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#printing out some stats and plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with dimesions:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#call as plt.imshow(gray, cmap='gray') to show a grayscaled image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bat/anaconda2/envs/opencv/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n",
      "\u001b[0;32m/home/bat/anaconda2/envs/opencv/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mpilread\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bat/anaconda2/envs/opencv/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2278\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'solidWhiteRight.jpg'"
     ]
    }
   ],
   "source": [
    "#reading in an image\n",
    "image = mpimg.imread('solidWhiteRight.jpg')\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image)  #call as plt.imshow(gray, cmap='gray') to show a grayscaled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "global avgRight\n",
    "global avgLeft\n",
    "\n",
    "def perp( a ) :\n",
    "    b = np.empty_like(a)\n",
    "    b[0] = -a[1]\n",
    "    b[1] = a[0]\n",
    "    return b\n",
    "\n",
    "# line segment a given by endpoints a1, a2\n",
    "# line segment b given by endpoints b1, b2\n",
    "# return \n",
    "def seg_intersect(a1,a2, b1,b2):\n",
    "    da = a2-a1\n",
    "    db = b2-b1\n",
    "    dp = a1-b1\n",
    "    dap = perp(da)\n",
    "    denom = np.dot( dap, db)\n",
    "    num = np.dot( dap, dp )\n",
    "    return (num / denom.astype(float))*db + b1\n",
    "\n",
    "def movingAverage(avg, new_sample, N=20):\n",
    "    if (avg == 0):\n",
    "        return new_sample\n",
    "    avg -= avg / N;\n",
    "    avg += new_sample / N;\n",
    "    return avg;\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "  \n",
    "    # state variables to keep track of most dominant segment\n",
    "    largestLeftLineSize = 0\n",
    "    largestRightLineSize = 0\n",
    "    largestLeftLine = (0,0,0,0)\n",
    "    largestRightLine = (0,0,0,0)\n",
    "\n",
    "    if lines is None:\n",
    "        avgx1, avgy1, avgx2, avgy2 = avgLeft\n",
    "        cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw left line\n",
    "        avgx1, avgy1, avgx2, avgy2 = avgRight\n",
    "        cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw right line\n",
    "        return\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            size = math.hypot(x2 - x1, y2 - y1)\n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "            # Filter slope based on incline and\n",
    "            # find the most dominent segment based on length\n",
    "            if (slope > 0.5): #right\n",
    "                if (size > largestRightLineSize):\n",
    "                    largestRightLine = (x1, y1, x2, y2)                    \n",
    "                cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            elif (slope < -0.5): #left\n",
    "                if (size > largestLeftLineSize):\n",
    "                    largestLeftLine = (x1, y1, x2, y2)\n",
    "                cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "    # Define an imaginary horizontal line in the center of the screen\n",
    "    # and at the bottom of the image, to extrapolate determined segment\n",
    "    imgHeight, imgWidth = (img.shape[0], img.shape[1])\n",
    "    upLinePoint1 = np.array( [0, int(imgHeight - (imgHeight/3))] )\n",
    "    upLinePoint2 = np.array( [int(imgWidth), int(imgHeight - (imgHeight/3))] )\n",
    "    downLinePoint1 = np.array( [0, int(imgHeight)] )\n",
    "    downLinePoint2 = np.array( [int(imgWidth), int(imgHeight)] )\n",
    "    \n",
    "    # Find the intersection of dominant lane with an imaginary horizontal line\n",
    "    # in the middle of the image and at the bottom of the image.\n",
    "    p3 = np.array( [largestLeftLine[0], largestLeftLine[1]] )\n",
    "    p4 = np.array( [largestLeftLine[2], largestLeftLine[3]] )\n",
    "    upLeftPoint = seg_intersect(upLinePoint1,upLinePoint2, p3,p4)\n",
    "    downLeftPoint = seg_intersect(downLinePoint1,downLinePoint2, p3,p4)\n",
    "    if (math.isnan(upLeftPoint[0]) or math.isnan(downLeftPoint[0])):\n",
    "        avgx1, avgy1, avgx2, avgy2 = avgLeft\n",
    "        cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw left line\n",
    "        avgx1, avgy1, avgx2, avgy2 = avgRight\n",
    "        cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw right line\n",
    "        return\n",
    "    cv2.line(img, (int(upLeftPoint[0]), int(upLeftPoint[1])), (int(downLeftPoint[0]), int(downLeftPoint[1])), [0, 0, 255], 8) #draw left line\n",
    "\n",
    "    # Calculate the average position of detected left lane over multiple video frames and draw\n",
    "    global avgLeft\n",
    "    avgx1, avgy1, avgx2, avgy2 = avgLeft\n",
    "    avgLeft = (movingAverage(avgx1, upLeftPoint[0]), movingAverage(avgy1, upLeftPoint[1]), movingAverage(avgx2, downLeftPoint[0]), movingAverage(avgy2, downLeftPoint[1]))\n",
    "    avgx1, avgy1, avgx2, avgy2 = avgLeft\n",
    "    cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw left line\n",
    "\n",
    "    # Find the intersection of dominant lane with an imaginary horizontal line\n",
    "    # in the middle of the image and at the bottom of the image.\n",
    "    p5 = np.array( [largestRightLine[0], largestRightLine[1]] )\n",
    "    p6 = np.array( [largestRightLine[2], largestRightLine[3]] )\n",
    "    upRightPoint = seg_intersect(upLinePoint1,upLinePoint2, p5,p6)\n",
    "    downRightPoint = seg_intersect(downLinePoint1,downLinePoint2, p5,p6)\n",
    "    if (math.isnan(upRightPoint[0]) or math.isnan(downRightPoint[0])):\n",
    "        avgx1, avgy1, avgx2, avgy2 = avgLeft\n",
    "        cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw left line\n",
    "        avgx1, avgy1, avgx2, avgy2 = avgRight\n",
    "        cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw right line\n",
    "        return\n",
    "    cv2.line(img, (int(upRightPoint[0]), int(upRightPoint[1])), (int(downRightPoint[0]), int(downRightPoint[1])), [0, 0, 255], 8) #draw left line\n",
    "\n",
    "    # Calculate the average position of detected right lane over multiple video frames and draw\n",
    "    global avgRight\n",
    "    avgx1, avgy1, avgx2, avgy2 = avgRight\n",
    "    avgRight = (movingAverage(avgx1, upRightPoint[0]), movingAverage(avgy1, upRightPoint[1]), movingAverage(avgx2, downRightPoint[0]), movingAverage(avgy2, downRightPoint[1]))\n",
    "    avgx1, avgy1, avgx2, avgy2 = avgRight\n",
    "    cv2.line(img, (int(avgx1), int(avgy1)), (int(avgx2), int(avgy2)), [255,255,255], 12) #draw left line\n",
    "\n",
    "    \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "def process_image(image):\n",
    "\n",
    "    # grayscale conversion before processing causes more harm than good\n",
    "    # because sometimes the lane and road have same amount of luminance\n",
    "    # grayscaleImage = grayscale(image)\n",
    "\n",
    "    # Blur to avoid edges from noise\n",
    "    blurredImage = gaussian_blur(image, 11)\n",
    "    \n",
    "    # Detect edges using canny\n",
    "    # high to low threshold factor of 3\n",
    "    # it is necessary to keep a linient threshold at the lower end\n",
    "    # to continue to detect faded lane markings\n",
    "    edgesImage = canny(blurredImage, 40, 50)\n",
    "    \n",
    "    # mark out the trapezium region of interest\n",
    "    # dont' be too agressive as the car may drift laterally\n",
    "    # while driving, hence ample space is still left on both sides.\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    vertices = np.array( [[\n",
    "                [3*width/4, 3*height/5],\n",
    "                [width/4, 3*height/5],\n",
    "                [40, height],\n",
    "                [width - 40, height]\n",
    "            ]], dtype=np.int32 )\n",
    "    \n",
    "    # mask the canny output with trapezium region of interest\n",
    "    regionInterestImage = region_of_interest(edgesImage, vertices)\n",
    "    \n",
    "    # parameters tuned using this method:\n",
    "    # threshold 30 by modifying it and seeing where slightly curved \n",
    "    # lane markings are barely detected\n",
    "    # min line length 20 by modifying and seeing where broken short\n",
    "    # lane markings are barely detected\n",
    "    # max line gap as 100 to allow plenty of room for the algo to \n",
    "    # connect spaced out lane markings\n",
    "    lineMarkedImage = hough_lines(regionInterestImage, 1, np.pi/180, 40, 30, 200)\n",
    "    \n",
    "    # Test detected edges by uncommenting this\n",
    "    # return cv2.cvtColor(regionInterestImage, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # draw output on top of original\n",
    "    return weighted_img(lineMarkedImage, image)\n",
    "\n",
    "\n",
    "# debug on images\n",
    "inDirectory = \"test_images\"\n",
    "outDirectory = inDirectory + \"_out\"\n",
    "if not os.path.exists(outDirectory):\n",
    "    os.makedirs(outDirectory)\n",
    "imageNames = os.listdir(inDirectory + \"/\")\n",
    "for imageName in imageNames:\n",
    "    avgLeft = (0, 0, 0, 0)\n",
    "    avgRight = (0, 0, 0, 0)\n",
    "    image = mpimg.imread(inDirectory + \"/\" + imageName)\n",
    "    out = process_image(image)\n",
    "    mpimg.imsave(outDirectory + \"/\" + imageName, out)\n",
    "    print(\"Processed \" + outDirectory + \"/\" + imageName)\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset global state of average values\n",
    "avgLeft = (0, 0, 0, 0)\n",
    "avgRight = (0, 0, 0, 0)\n",
    "\n",
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset global state of average values\n",
    "avgLeft = (0, 0, 0, 0)\n",
    "avgRight = (0, 0, 0, 0)\n",
    "\n",
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:opencv]",
   "language": "python",
   "name": "conda-env-opencv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
